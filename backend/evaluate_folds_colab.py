# -*- coding: utf-8 -*-
"""
Colabì—ì„œ í•™ìŠµëœ k-fold ëª¨ë¸ë“¤ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš© ë°©ë²•:
1. Colabì—ì„œ ì´ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ë‚´ìš©ì„ ë³µì‚¬
2. Colab ì…€ì—ì„œ ì‹¤í–‰
3. ê° fold ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ì—¬ ê°€ì¥ ì¢‹ì€ ëª¨ë¸ ì°¾ê¸°
"""

import os
import time
from pathlib import Path
from typing import List, Dict, Tuple
import torch
import numpy as np
from sklearn.model_selection import KFold
from transformers import AutoTokenizer, AutoModelForCausalLM
from datasets import load_dataset
import re

# ===== ì„¤ì • =====
MODEL_ID = "skt/kogpt2-base-v2"
BASE_MODEL_DIR = "./kogpt2_finetuned"
MAX_DATA_SIZE = 100  # í‰ê°€ì— ì‚¬ìš©í•  ë°ì´í„° ê°œìˆ˜
K_FOLDS = 5


def download_kpoem_data(max_size: int = 100) -> List[Dict]:
    """KPoeM ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ"""
    print(f"\n{'='*80}")
    print(f"[KPoeM ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ]")
    print(f"  - ìµœëŒ€ ê°œìˆ˜: {max_size}")
    print(f"{'='*80}\n")
    
    try:
        dataset = load_dataset(
            "csv",
            data_files={
                "train": "hf://datasets/AKS-DHLAB/KPoEM/KPoEM_poem_dataset_v4.tsv"
            },
            delimiter="\t",
            encoding="utf-8",
            quoting=3,
        )
        dataset = dataset["train"]
        
        normalized_data = []
        for i, item in enumerate(dataset):
            if max_size and i >= max_size:
                break
            if 'text' in item and item['text']:
                poem_text = str(item['text']).strip()
                normalized_data.append({
                    'text': poem_text,
                    'poem': poem_text
                })
        
        print(f"âœ… {len(normalized_data)}ê°œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        return normalized_data
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise


def extract_keywords_simple(text: str, max_keywords: int = 10) -> List[str]:
    """ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    words = text.split()
    keywords = [w for w in words if len(w) >= 2][:max_keywords]
    return keywords if keywords else ["ì‹œ", "ê°ì •"]


def classify_emotion_simple(text: str) -> Dict[str, str]:
    """ê°„ë‹¨í•œ ê°ì • ë¶„ë¥˜"""
    positive_words = ["ì¢‹", "í–‰ë³µ", "ê¸°ì¨", "ì‚¬ë‘", "í¬ë§", "ë°", "ë”°ëœ»"]
    negative_words = ["ìŠ¬", "ìš°ìš¸", "ì•„í””", "í˜ë“¦", "ì–´ë‘ ", "ì°¨ê°‘"]
    
    text_lower = text.lower()
    pos_count = sum(1 for word in positive_words if word in text_lower)
    neg_count = sum(1 for word in negative_words if word in text_lower)
    
    if pos_count > neg_count:
        mood = "ë°ì€"
    elif neg_count > pos_count:
        mood = "ì–´ë‘ìš´"
    else:
        mood = "ì”ì”í•œ"
    
    return {'mood': mood}


def build_prompt_kogpt2(keywords: List[str], mood: str, lines: int, original_text: str) -> str:
    """koGPT2ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    kw_str = ", ".join(keywords[:10])
    
    prompt = f"""Write a Korean poem (í•œêµ­ì–´ ì‹œ) based on the keywords and mood below.

**CRITICAL: Language Requirement**
- You MUST write ONLY in Korean (Hangul, í•œê¸€).
- Do NOT use Chinese characters (í•œì), Japanese characters, English, or any other language.
- Use ONLY Korean characters (ê°€-í£) and Korean punctuation.
- The output MUST be a Korean poem.

**Output Requirements**
- Output ONLY the poem text (no title, no explanation, no keywords, no numbering).
- The output MUST be in poem form with line breaks.
- Write EXACTLY {lines} lines (one line per verse; no empty lines).

**Content**
- Keywords: {kw_str}
- Mood: {mood}
{f'**Original Prose (Context)**\n\"\"\"{original_text.strip()}\"\"\"\n' if original_text else ''}

**Style Rules (strict)**
1) Keep each line short and lyrical.
2) Show, don't tell.
3) Avoid plain narration and diary-like tone.
4) In Korean, avoid declarative endings like "~ë‹¤", "~ì´ë‹¤", "~í–ˆë‹¤".
5) Avoid explicit subjects/time markers like "ë‚˜ëŠ”", "ê·¸ëŠ”/ê·¸ë…€ëŠ”", "ì˜¤ëŠ˜ì€/ì–´ì œëŠ”".

Poem:
"""
    return prompt


def generate_poem_with_model(
    model_path: str,
    tokenizer: AutoTokenizer,
    model: AutoModelForCausalLM,
    keywords: List[str],
    mood: str,
    original_text: str,
    device: str
) -> str:
    """
    í•™ìŠµëœ ëª¨ë¸ë¡œ ì‹œ ìƒì„±
    í•™ìŠµ ë°©ì‹: ì‚°ë¬¸ì˜ ì˜ë¯¸ë¥¼ ì´í•´í•˜ê³  ê·¸ì— ë§ëŠ” ì‹œë¥¼ ìƒì„±
    """
    # í•™ìŠµ í˜•ì‹: "ì‚°ë¬¸: [ë‚´ìš©]\nì‹œ: [ë‚´ìš©]"
    # ë”°ë¼ì„œ ì…ë ¥ì€ "ì‚°ë¬¸: [ë‚´ìš©]\nì‹œ: " í˜•ì‹ìœ¼ë¡œ ì œê³µ
    # ëª¨ë¸ì´ ì‚°ë¬¸ì˜ ì˜ë¯¸ë¥¼ ì´í•´í•˜ê³  ê·¸ì— ë§ëŠ” ì‹œë¥¼ ìƒì„±í•˜ë„ë¡ í•¨
    input_text = f"ì‚°ë¬¸: {original_text.strip()}\nì‹œ: "
    
    # í† í¬ë‚˜ì´ì¦ˆ
    enc_ids = tokenizer.encode(input_text, return_tensors="pt").to(device)
    prompt_length = enc_ids.shape[1]
    
    # ì…ë ¥ í† í° ê¸¸ì´ ì œí•œ
    max_pos_embeddings = getattr(model.config, 'max_position_embeddings', 1024)
    safe_max_input = max_pos_embeddings - 100
    if enc_ids.shape[1] >= safe_max_input:
        enc_ids = enc_ids[:, :safe_max_input]
        prompt_length = enc_ids.shape[1]
    
    # ì‹œ ìƒì„±
    with torch.no_grad():
        output = model.generate(
            enc_ids,
            max_new_tokens=200,
            temperature=0.8,
            top_p=0.95,
            top_k=50,
            repetition_penalty=1.2,
            no_repeat_ngram_size=3,
            do_sample=True,
            pad_token_id=tokenizer.eos_token_id,
            eos_token_id=tokenizer.eos_token_id,
        )
    
    # ë””ì½”ë”©
    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)
    
    # í”„ë¡¬í”„íŠ¸ ì œê±° (í† í° ê¸°ì¤€ìœ¼ë¡œ ì œê±°)
    # output[0]ì€ [prompt_tokens + generated_tokens] í˜•íƒœ
    # prompt_length ì´í›„ì˜ í† í°ë§Œ ë””ì½”ë”©
    if len(output[0]) > prompt_length:
        generated_tokens = output[0][prompt_length:]
        poem = tokenizer.decode(generated_tokens, skip_special_tokens=True)
    else:
        # í† í° ê¸°ì¤€ ì œê±°ê°€ ì•ˆ ë˜ë©´ í…ìŠ¤íŠ¸ ê¸°ì¤€ìœ¼ë¡œ ì‹œë„
        # "ì‚°ë¬¸: ...\nì‹œ: " íŒ¨í„´ ì œê±°
        if "ì‹œ: " in generated_text:
            poem = generated_text.split("ì‹œ: ", 1)[1].strip()
        else:
            poem = generated_text.strip()
    
    # í”„ë¡¬í”„íŠ¸ íŒ¨í„´ ì œê±° (í˜¹ì‹œ ëª¨ë¥¼ ê²½ìš°ë¥¼ ëŒ€ë¹„)
    # "Poem:", "ì‹œ:", "Write a Korean poem" ë“±ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ë¶€ë¶„ ì œê±°
    prompt_patterns = [
        r'^Write a Korean poem.*?\n',
        r'^Poem:\s*',
        r'^ì‹œ:\s*',
        r'^\*\*CRITICAL.*?\n',
        r'^\*\*Output.*?\n',
    ]
    
    for pattern in prompt_patterns:
        poem = re.sub(pattern, '', poem, flags=re.IGNORECASE | re.MULTILINE | re.DOTALL)
    
    poem = poem.strip()
    
    # í›„ì²˜ë¦¬: ë¹ˆ ì¤„ ì œê±° ë° ì¤„ ìˆ˜ ì œí•œ
    poem_lines = [line.strip() for line in poem.split('\n') if line.strip()]
    
    # í”„ë¡¬í”„íŠ¸ê°€ í¬í•¨ëœ ì¤„ ì œê±°
    filtered_lines = []
    for line in poem_lines:
        # í”„ë¡¬í”„íŠ¸ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ì¤„ ì œê±°
        if any(keyword in line.lower() for keyword in ['write a korean', 'critical', 'language requirement', 'output requirements', 'style rules']):
            continue
        # ì˜ì–´ë§Œ ìˆëŠ” ì¤„ ì œê±° (í•œê¸€ì´ ì—†ìœ¼ë©´)
        if not any(ord('ê°€') <= ord(c) <= ord('í£') for c in line):
            if len(line) > 20:  # ê¸´ ì˜ì–´ ì¤„ì€ í”„ë¡¬í”„íŠ¸ì¼ ê°€ëŠ¥ì„±
                continue
        filtered_lines.append(line)
    
    poem = '\n'.join(filtered_lines[:6]) if filtered_lines else poem
    
    # ìµœì¢… ê²€ì¦: ì—¬ì „íˆ í”„ë¡¬í”„íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
    if any(keyword in poem.lower()[:100] for keyword in ['write a korean poem', 'critical: language requirement']):
        print(f"    âš ï¸ í”„ë¡¬í”„íŠ¸ê°€ í¬í•¨ëœ ì¶œë ¥ ê°ì§€, ë¹ˆ ë¬¸ìì—´ ë°˜í™˜")
        return ""
    
    return poem


def calculate_similarity(text1: str, text2: str) -> float:
    """ë‘ í…ìŠ¤íŠ¸ì˜ ìœ ì‚¬ë„ ê³„ì‚° (ê°„ë‹¨í•œ ë°©ë²•)"""
    # ë‹¨ì–´ ê¸°ë°˜ ìœ ì‚¬ë„
    words1 = set(text1.split())
    words2 = set(text2.split())
    
    if not words1 or not words2:
        return 0.0
    
    intersection = words1.intersection(words2)
    union = words1.union(words2)
    
    return len(intersection) / len(union) if union else 0.0


def evaluate_keyword_relevance(original_text: str, keywords: List[str], generated_poem: str) -> Dict[str, float]:
    """
    ìƒì„±ëœ ì‹œê°€ ì›ë³¸ í…ìŠ¤íŠ¸ì˜ í‚¤ì›Œë“œë¥¼ ì–¼ë§ˆë‚˜ ë°˜ì˜í–ˆëŠ”ì§€ í‰ê°€í•©ë‹ˆë‹¤.
    
    Args:
        original_text: ì›ë³¸ ì¼ìƒ ê¸€
        keywords: ì¶”ì¶œëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        generated_poem: ìƒì„±ëœ ì‹œ
    
    Returns:
        í‚¤ì›Œë“œ ê´€ë ¨ì„± í‰ê°€ ë”•ì…”ë„ˆë¦¬
    """
    if not generated_poem or not keywords:
        return {
            'keyword_coverage': 0.0,
            'keyword_count': 0,
            'total_keywords': len(keywords),
            'keyword_score': 0.0
        }
    
    # ìƒì„±ëœ ì‹œì—ì„œ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê°œìˆ˜
    found_keywords = []
    for keyword in keywords:
        # í‚¤ì›Œë“œê°€ ì§ì ‘ í¬í•¨ë˜ì–´ ìˆê±°ë‚˜, ë¶€ë¶„ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
        if keyword in generated_poem:
            found_keywords.append(keyword)
        else:
            # ë¶€ë¶„ ì¼ì¹˜ í™•ì¸ (2ê¸€ì ì´ìƒì¸ ê²½ìš°)
            if len(keyword) >= 2:
                for i in range(len(generated_poem) - len(keyword) + 1):
                    if generated_poem[i:i+len(keyword)] == keyword:
                        found_keywords.append(keyword)
                        break
    
    keyword_count = len(found_keywords)
    total_keywords = len(keywords)
    keyword_coverage = keyword_count / total_keywords if total_keywords > 0 else 0.0
    
    # í‚¤ì›Œë“œ ì ìˆ˜: ëª¨ë“  í‚¤ì›Œë“œê°€ í¬í•¨ë˜ë©´ 1.0, ì ˆë°˜ ì´ìƒì´ë©´ 0.7, ì¼ë¶€ë§Œ ìˆìœ¼ë©´ 0.4
    if keyword_coverage >= 0.8:  # 80% ì´ìƒ
        keyword_score = 1.0
    elif keyword_coverage >= 0.5:  # 50% ì´ìƒ
        keyword_score = 0.7
    elif keyword_coverage >= 0.3:  # 30% ì´ìƒ
        keyword_score = 0.4
    else:
        keyword_score = keyword_coverage * 0.5  # 30% ë¯¸ë§Œì€ ë¹„ë¡€ì ìœ¼ë¡œ ë‚®ì€ ì ìˆ˜
    
    return {
        'keyword_coverage': keyword_coverage,
        'keyword_count': keyword_count,
        'total_keywords': total_keywords,
        'found_keywords': found_keywords,
        'missing_keywords': [kw for kw in keywords if kw not in found_keywords],
        'keyword_score': keyword_score
    }


def evaluate_emotion_relevance(original_text: str, original_mood: str, generated_poem: str) -> Dict[str, float]:
    """
    ìƒì„±ëœ ì‹œê°€ ì›ë³¸ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ì–¼ë§ˆë‚˜ ë°˜ì˜í–ˆëŠ”ì§€ í‰ê°€í•©ë‹ˆë‹¤.
    
    Args:
        original_text: ì›ë³¸ ì¼ìƒ ê¸€
        original_mood: ì›ë³¸ í…ìŠ¤íŠ¸ì˜ ê°ì •/ë¶„ìœ„ê¸° (ì˜ˆ: "ë°ì€", "ì–´ë‘ìš´", "ì”ì”í•œ")
        generated_poem: ìƒì„±ëœ ì‹œ
    
    Returns:
        ê°ì • ê´€ë ¨ì„± í‰ê°€ ë”•ì…”ë„ˆë¦¬
    """
    if not generated_poem:
        return {
            'emotion_match': 0.0,
            'emotion_score': 0.0,
            'detected_mood': 'unknown'
        }
    
    # ê°ì • ë‹¨ì–´ ì‚¬ì „
    positive_words = ["ì¢‹", "í–‰ë³µ", "ê¸°ì¨", "ì‚¬ë‘", "í¬ë§", "ë°", "ë”°ëœ»", "ì›ƒ", "ì¦ê±°", "í™˜", "ë¹›", "ë³„", "ê½ƒ", "ë´„"]
    negative_words = ["ìŠ¬", "ìš°ìš¸", "ì•„í””", "í˜ë“¦", "ì–´ë‘ ", "ì°¨ê°‘", "ëˆˆë¬¼", "ê·¸ë¦¬ì›€", "ì™¸ë¡œì›€", "ì•„í””", "ê³ í†µ"]
    neutral_words = ["ì”ì”", "í‰ì˜¨", "ê³ ìš”", "ì¡°ìš©", "ì°¨ë¶„", "í‰í™”"]
    
    # ìƒì„±ëœ ì‹œì—ì„œ ê°ì • ë‹¨ì–´ ì°¾ê¸°
    poem_lower = generated_poem.lower()
    positive_count = sum(1 for word in positive_words if word in poem_lower)
    negative_count = sum(1 for word in negative_words if word in poem_lower)
    neutral_count = sum(1 for word in neutral_words if word in poem_lower)
    
    # ìƒì„±ëœ ì‹œì˜ ê°ì • íŒì •
    if positive_count > negative_count and positive_count > neutral_count:
        detected_mood = "ë°ì€"
    elif negative_count > positive_count and negative_count > neutral_count:
        detected_mood = "ì–´ë‘ìš´"
    elif neutral_count > 0:
        detected_mood = "ì”ì”í•œ"
    else:
        detected_mood = "ì¤‘ë¦½"
    
    # ì›ë³¸ ê°ì •ê³¼ ìƒì„±ëœ ì‹œì˜ ê°ì • ì¼ì¹˜ë„
    emotion_match = 0.0
    if original_mood == detected_mood:
        emotion_match = 1.0
    elif (original_mood == "ë°ì€" and detected_mood == "ì–´ë‘ìš´") or (original_mood == "ì–´ë‘ìš´" and detected_mood == "ë°ì€"):
        emotion_match = 0.0  # ì •ë°˜ëŒ€
    elif (original_mood == "ë°ì€" and detected_mood == "ì”ì”í•œ") or (original_mood == "ì–´ë‘ìš´" and detected_mood == "ì”ì”í•œ"):
        emotion_match = 0.5  # ë¶€ë¶„ ì¼ì¹˜
    elif original_mood == "ì”ì”í•œ" and detected_mood in ["ë°ì€", "ì–´ë‘ìš´"]:
        emotion_match = 0.5  # ë¶€ë¶„ ì¼ì¹˜
    else:
        emotion_match = 0.3  # ì•½ê°„ ì¼ì¹˜
    
    # ê°ì • ì ìˆ˜: ì¼ì¹˜ë„ + ê°ì • ë‹¨ì–´ ì‚¬ìš© ë¹ˆë„
    emotion_word_score = min(1.0, (positive_count + negative_count + neutral_count) / 3.0)
    emotion_score = (emotion_match * 0.7) + (emotion_word_score * 0.3)
    
    return {
        'emotion_match': emotion_match,
        'emotion_score': emotion_score,
        'detected_mood': detected_mood,
        'original_mood': original_mood,
        'positive_count': positive_count,
        'negative_count': negative_count,
        'neutral_count': neutral_count
    }


def evaluate_poetry_quality(poem: str) -> Dict[str, float]:
    """
    ìƒì„±ëœ í…ìŠ¤íŠ¸ê°€ ì§„ì§œ ì‹œì¸ì§€ í‰ê°€í•©ë‹ˆë‹¤.
    ì‹œê°€ ì•„ë‹Œ ì‚°ë¬¸, ì¼ê¸°, ì„¤ëª…ë¬¸ ë“±ì„ ê°•í•˜ê²Œ ê°ì§€í•©ë‹ˆë‹¤.
    
    Returns:
        í‰ê°€ ì ìˆ˜ ë”•ì…”ë„ˆë¦¬ (ê° í•­ëª© 0.0~1.0)
    """
    if not poem or len(poem.strip()) == 0:
        return {
            'is_poetry': 0.0,
            'format_score': 0.0,
            'korean_score': 0.0,
            'prose_penalty': 1.0,  # ìµœëŒ€ íŒ¨ë„í‹°
            'poetry_bonus': 0.0,
            'length_score': 0.0,
            'overall_score': 0.0,
            'is_prose': True,
            'is_diary': False,
            'is_explanation': False
        }
    
    poem = poem.strip()
    lines = [line.strip() for line in poem.split('\n') if line.strip()]
    
    # ===== 1. í˜•ì‹ ì ìˆ˜ (ì¤„ë°”ê¿ˆ, ì¤„ ê°œìˆ˜, ì¤„ ê¸¸ì´) =====
    format_score = 0.0
    
    # ì¤„ ê°œìˆ˜ ì ìˆ˜
    if len(lines) >= 3:  # ìµœì†Œ 3ì¤„ ì´ìƒ
        format_score += 0.2
    if len(lines) >= 6:  # 6ì¤„ ì´ìƒ (ì´ìƒì )
        format_score += 0.3
    
    # ì¤„ ê¸¸ì´ ì ìˆ˜ (ê° ì¤„ì´ 5-20ì ì •ë„ë©´ ì¢‹ìŒ)
    good_length_lines = 0
    very_long_lines = 0  # 30ì ì´ìƒì€ ì‚°ë¬¸ì¼ ê°€ëŠ¥ì„±
    for line in lines:
        line_len = len(line)
        if 5 <= line_len <= 20:  # ì ì ˆí•œ ê¸¸ì´
            good_length_lines += 1
        elif line_len > 30:  # ë„ˆë¬´ ê¸´ ì¤„ (ì‚°ë¬¸ ê°€ëŠ¥ì„±)
            very_long_lines += 1
    
    if lines:
        format_score += 0.5 * (good_length_lines / len(lines))
        # ë„ˆë¬´ ê¸´ ì¤„ì´ ë§ìœ¼ë©´ ê°ì 
        if very_long_lines > len(lines) * 0.3:  # 30% ì´ìƒì´ë©´
            format_score *= 0.7
    
    # ===== 2. í•œêµ­ì–´ ì ìˆ˜ =====
    korean_chars = sum(1 for c in poem if ord('ê°€') <= ord(c) <= ord('í£'))
    total_chars = len([c for c in poem if c.strip()])
    korean_score = korean_chars / total_chars if total_chars > 0 else 0.0
    
    # ===== 3. ì‚°ë¬¸ íŒ¨í„´ ê°•ë ¥ ê°ì§€ =====
    prose_penalty = 0.0
    is_prose = False
    is_diary = False
    is_explanation = False
    
    # ì„ ì–¸ì  ì¢…ê²°ì–´ë¯¸ íŒ¨í„´ (ë” ê°•ë ¥í•˜ê²Œ)
    declarative_patterns = [
        r'[ê°€-í£\s]+ë‹¤\s*[\.ã€‚]',  # "~ë‹¤."
        r'[ê°€-í£\s]+ì´ë‹¤\s*[\.ã€‚]',  # "~ì´ë‹¤."
        r'[ê°€-í£\s]+í–ˆë‹¤\s*[\.ã€‚]',  # "~í–ˆë‹¤."
        r'[ê°€-í£\s]+ê°”ë‹¤\s*[\.ã€‚]',  # "~ê°”ë‹¤."
        r'[ê°€-í£\s]+í–ˆë‹¤\s*[\.ã€‚]',  # "~í–ˆë‹¤."
        r'[ê°€-í£\s]+ì´ë‹¤\s*[\.ã€‚]',  # "~ì´ë‹¤."
        r'[ê°€-í£\s]+ì´ë‹¤\s*$',  # ì¤„ ëì˜ "~ì´ë‹¤"
        r'[ê°€-í£\s]+ë‹¤\s*$',  # ì¤„ ëì˜ "~ë‹¤"
    ]
    
    declarative_count = 0
    for pattern in declarative_patterns:
        matches = re.findall(pattern, poem)
        declarative_count += len(matches)
    
    # ì£¼ì–´/ì‹œê°„ í‘œì‹œ íŒ¨í„´ (ì¼ê¸°, ì‚°ë¬¸ íŠ¹ì§•)
    subject_time_patterns = [
        r'\bë‚˜ëŠ”\b',
        r'\bê·¸ëŠ”\b',
        r'\bê·¸ë…€ëŠ”\b',
        r'\bìš°ë¦¬ëŠ”\b',
        r'\bì˜¤ëŠ˜ì€\b',
        r'\bì–´ì œëŠ”\b',
        r'\bë‚´ì¼ì€\b',
        r'\bì˜¤ëŠ˜\b.*[ì€ëŠ”]',  # "ì˜¤ëŠ˜ì€", "ì˜¤ëŠ˜ì˜"
        r'\bì–´ì œ\b.*[ì€ëŠ”]',
    ]
    
    subject_time_count = 0
    for pattern in subject_time_patterns:
        subject_time_count += len(re.findall(pattern, poem))
    
    # ì¼ê¸° íŒ¨í„´ ê°ì§€
    diary_patterns = [
        r'ì˜¤ëŠ˜.*[ì€ëŠ”]',
        r'ì–´ì œ.*[ì€ëŠ”]',
        r'ë‚´ì¼.*[ì€ëŠ”]',
        r'ë‚˜ëŠ”.*[í–ˆê°”]ë‹¤',
        r'ì˜¤ëŠ˜.*[í–ˆê°”]ë‹¤',
    ]
    
    diary_count = sum(len(re.findall(pattern, poem)) for pattern in diary_patterns)
    if diary_count >= 3:  # 2 â†’ 3ìœ¼ë¡œ ì™„í™”
        is_diary = True
    
    # ì„¤ëª…ë¬¸/ë…¼ìˆ  íŒ¨í„´
    explanation_patterns = [
        r'[ê°€-í£]+[ì€ëŠ”]?\s*[ê°€-í£]+[ì´ë‹¤]',  # "AëŠ” Bì´ë‹¤"
        r'[ê°€-í£]+[ì€ëŠ”]?\s*[ê°€-í£]+[ì´ë‹¤]',  # "AëŠ” Bì´ë‹¤"
        r'ì™œëƒí•˜ë©´',
        r'ê·¸ë˜ì„œ',
        r'ë”°ë¼ì„œ',
        r'ê·¸ëŸ¬ë¯€ë¡œ',
    ]
    
    explanation_count = sum(len(re.findall(pattern, poem)) for pattern in explanation_patterns)
    if explanation_count >= 3:  # 2 â†’ 3ìœ¼ë¡œ ì™„í™”
        is_explanation = True
    
    # ì‚°ë¬¸ íŒì •: ì„ ì–¸ì  ì¢…ê²°ì–´ë¯¸ê°€ ë§ê±°ë‚˜, ì£¼ì–´/ì‹œê°„ í‘œì‹œê°€ ë§ìœ¼ë©´ (ê¸°ì¤€ ì™„í™”)
    if declarative_count >= 5 or subject_time_count >= 5:  # 3 â†’ 5ë¡œ ì™„í™”
        is_prose = True
    
    # íŒ¨ë„í‹° ê³„ì‚° (ë” ê°•ë ¥í•˜ê²Œ)
    total_penalty_score = (
        declarative_count * 0.15 +  # ì„ ì–¸ì  ì¢…ê²°ì–´ë¯¸ëŠ” ê°•í•˜ê²Œ ê°ì 
        subject_time_count * 0.10 +  # ì£¼ì–´/ì‹œê°„ í‘œì‹œ ê°ì 
        diary_count * 0.20 +  # ì¼ê¸° íŒ¨í„´ì€ ë” ê°•í•˜ê²Œ ê°ì 
        explanation_count * 0.15  # ì„¤ëª…ë¬¸ íŒ¨í„´ ê°ì 
    )
    
    # ìµœëŒ€ íŒ¨ë„í‹°ëŠ” 0.8 (80% ê°ì )
    prose_penalty = min(0.8, total_penalty_score)
    
    # ===== 4. ì‹œì  í‘œí˜„ ë³´ë„ˆìŠ¤ =====
    poetry_bonus = 0.0
    
    # ì€ìœ , ìƒì§• í‘œí˜„
    poetic_patterns = [
        r'[ê°€-í£]+ì²˜ëŸ¼',  # "ê½ƒì²˜ëŸ¼", "ë³„ì²˜ëŸ¼"
        r'[ê°€-í£]+ê°™ì´',  # "ê½ƒê°™ì´"
        r'[ê°€-í£]+[ì€ëŠ”]?\s*[ê°€-í£]+[ì„ë¥¼]\s*[ê°€-í£]+',  # "ë°”ëŒì´ ê½ƒì„ í”ë“ ë‹¤" (ì‹œì  í‘œí˜„)
        r'[ê°€-í£]+[ì€ëŠ”]?\s*[ê°€-í£]+[ì—]?\s*[ê°€-í£]+',  # "í•˜ëŠ˜ì— ë³„ì´"
    ]
    
    poetic_count = sum(len(re.findall(pattern, poem)) for pattern in poetic_patterns)
    if poetic_count >= 2:
        poetry_bonus += 0.2
    elif poetic_count >= 1:
        poetry_bonus += 0.1
    
    # ì§§ê³  í•¨ì¶•ì ì¸ ì¤„ (ì‹œì  íŠ¹ì§•)
    short_lyrical_lines = sum(1 for line in lines if 3 <= len(line) <= 15)
    if len(lines) > 0 and short_lyrical_lines / len(lines) >= 0.7:  # 70% ì´ìƒì´ë©´
        poetry_bonus += 0.1
    
    # ===== 5. ê¸¸ì´ ì ìˆ˜ =====
    length_score = 1.0
    poem_length = len(poem)
    if poem_length < 20:  # ë„ˆë¬´ ì§§ìŒ
        length_score = 0.2
    elif poem_length < 50:  # ì•½ê°„ ì§§ìŒ
        length_score = 0.6
    elif poem_length > 500:  # ë„ˆë¬´ ê¹€ (ì‚°ë¬¸ ê°€ëŠ¥ì„±)
        length_score = 0.7
    
    # ===== 6. ì˜ë¯¸ ìˆëŠ” ë‚´ìš© =====
    meaningful_score = 1.0
    if korean_chars < 10:  # í•œê¸€ì´ ë„ˆë¬´ ì ìŒ
        meaningful_score = 0.2
    elif korean_chars < 20:
        meaningful_score = 0.5
    elif korean_chars < 30:
        meaningful_score = 0.8
    
    # ===== 7. ì¢…í•© ì ìˆ˜ ê³„ì‚° =====
    # ê¸°ë³¸ ì ìˆ˜: í˜•ì‹ 25% + í•œêµ­ì–´ 20% + ê¸¸ì´ 15% + ì˜ë¯¸ 15%
    base_score = (
        format_score * 0.25 +
        korean_score * 0.20 +
        length_score * 0.15 +
        meaningful_score * 0.15
    )
    
    # ì‚°ë¬¸ íŒ¨ë„í‹° ì ìš© (25% ê°€ì¤‘ì¹˜)
    penalty_adjusted_score = base_score * (1.0 - prose_penalty * 0.25)
    
    # ì‹œì  í‘œí˜„ ë³´ë„ˆìŠ¤ ì¶”ê°€ (25% ê°€ì¤‘ì¹˜)
    overall_score = penalty_adjusted_score + (poetry_bonus * 0.25)
    
    # ì‚°ë¬¸/ì¼ê¸°/ì„¤ëª…ë¬¸ì´ë©´ ê°•í•˜ê²Œ ê°ì 
    if is_prose:
        overall_score *= 0.5  # 50% ì¶”ê°€ ê°ì 
    if is_diary:
        overall_score *= 0.6  # 40% ì¶”ê°€ ê°ì 
    if is_explanation:
        overall_score *= 0.7  # 30% ì¶”ê°€ ê°ì 
    
    # ìµœì†Œ 0.0, ìµœëŒ€ 1.0ìœ¼ë¡œ ì œí•œ
    overall_score = max(0.0, min(1.0, overall_score))
    
    return {
        'is_poetry': overall_score,  # 0.0 (ì‚°ë¬¸) ~ 1.0 (ì‹œ)
        'format_score': format_score,
        'korean_score': korean_score,
        'prose_penalty': prose_penalty,
        'poetry_bonus': poetry_bonus,
        'length_score': length_score,
        'meaningful_score': meaningful_score,
        'overall_score': overall_score,
        'line_count': len(lines),
        'korean_chars': korean_chars,
        'declarative_count': declarative_count,
        'subject_time_count': subject_time_count,
        'diary_count': diary_count,
        'explanation_count': explanation_count,
        'poetic_count': poetic_count,
        'is_prose': is_prose,
        'is_diary': is_diary,
        'is_explanation': is_explanation
    }


def evaluate_fold_model(
    fold_idx: int,
    model_path: Path,
    test_data: List[Dict],
    device: str
) -> Dict:
    """íŠ¹ì • fold ëª¨ë¸ í‰ê°€"""
    print(f"\n{'='*80}")
    print(f"[Fold {fold_idx} ëª¨ë¸ í‰ê°€]")
    print(f"  ëª¨ë¸ ê²½ë¡œ: {model_path}")
    print(f"  Test ë°ì´í„°: {len(test_data)}ê°œ")
    print(f"{'='*80}\n")
    
    if not model_path.exists():
        print(f"âŒ ëª¨ë¸ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_path}")
        return {
            'fold': fold_idx,
            'success': False,
            'error': 'Model path not found'
        }
    
    # ëª¨ë¸ ë¡œë“œ
    print(f"[1/3] ëª¨ë¸ ë¡œë”© ì¤‘...")
    try:
        tokenizer = AutoTokenizer.from_pretrained(str(model_path))
        model = AutoModelForCausalLM.from_pretrained(
            str(model_path),
            torch_dtype=torch.float32
        )
        model = model.to(device).eval()
        print(f"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ\n")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        return {
            'fold': fold_idx,
            'success': False,
            'error': str(e)
        }
    
    # ì‹œ ìƒì„± ë° í‰ê°€
    print(f"[2/3] ì‹œ ìƒì„± ë° í‰ê°€ ì¤‘...")
    results = []
    similarities = []
    success_count = 0
    
    # ë””ë²„ê¹…: ìƒì„±ëœ ì‹œ ìƒ˜í”Œ ì¶œë ¥
    sample_count = 0
    
    for i, item in enumerate(test_data, 1):
        if i % 5 == 0 or i == len(test_data):
            print(f"  ì§„í–‰ ì¤‘: {i}/{len(test_data)}")
        
        text = item['text']
        original_poem = item.get('poem', '')
        
        try:
            # í‚¤ì›Œë“œ ë° ê°ì • ì¶”ì¶œ
            keywords = extract_keywords_simple(text, max_keywords=10)
            emotion_result = classify_emotion_simple(text)
            mood = emotion_result.get('mood', 'ì”ì”í•œ')
            
            # ì‹œ ìƒì„±
            generated_poem = generate_poem_with_model(
                str(model_path),
                tokenizer,
                model,
                keywords,
                mood,
                text,
                device
            )
            
            # ë””ë²„ê¹…: ì²˜ìŒ ëª‡ ê°œ ìƒ˜í”Œ ì¶œë ¥
            if sample_count < 3:
                print(f"\n    [ìƒ˜í”Œ {sample_count + 1}]")
                print(f"      ì›ë¬¸: {text[:50]}...")
                print(f"      ìƒì„±ëœ ì‹œ ê¸¸ì´: {len(generated_poem) if generated_poem else 0}ì")
                print(f"      ìƒì„±ëœ ì‹œ: {repr(generated_poem[:200]) if generated_poem else 'None'}")
                if generated_poem:
                    korean_chars = sum(1 for c in generated_poem if ord('ê°€') <= ord(c) <= ord('í£'))
                    print(f"      í•œê¸€ ë¬¸ì ìˆ˜: {korean_chars}ì")
                sample_count += 1
            
            # ì‹œ í’ˆì§ˆ í‰ê°€
            poetry_quality = evaluate_poetry_quality(generated_poem) if generated_poem else {
                'is_poetry': 0.0,
                'overall_score': 0.0,
                'korean_chars': 0,
                'format_score': 0.0,
                'korean_score': 0.0,
                'prose_penalty': 0.0
            }
            
            # í‚¤ì›Œë“œ ê´€ë ¨ì„± í‰ê°€
            keyword_relevance = evaluate_keyword_relevance(text, keywords, generated_poem) if generated_poem else {
                'keyword_coverage': 0.0,
                'keyword_score': 0.0,
                'keyword_count': 0,
                'total_keywords': len(keywords)
            }
            
            # ê°ì • ê´€ë ¨ì„± í‰ê°€
            emotion_relevance = evaluate_emotion_relevance(text, mood, generated_poem) if generated_poem else {
                'emotion_match': 0.0,
                'emotion_score': 0.0,
                'detected_mood': 'unknown',
                'original_mood': mood
            }
            
            # ìœ ì‚¬ë„ ê³„ì‚° (ì›ë³¸ ì‹œì™€ì˜ ìœ ì‚¬ë„ - ì°¸ê³ ìš©)
            similarity = 0.0
            if generated_poem and original_poem:
                similarity = calculate_similarity(generated_poem, original_poem)
                similarities.append(similarity)
            
            # ì¢…í•© ì„±ê³µ ê¸°ì¤€: ì‹œ í˜•íƒœ + í‚¤ì›Œë“œ ë°˜ì˜ + ê°ì • ë°˜ì˜
            # 1. ì‹œ í’ˆì§ˆ ì ìˆ˜ê°€ 0.6 ì´ìƒ
            # 2. ì‚°ë¬¸/ì¼ê¸°/ì„¤ëª…ë¬¸ì´ ì•„ë‹˜
            # 3. í•œê¸€ì´ ì¶©ë¶„íˆ ìˆìŒ
            # 4. ìµœì†Œ ê¸¸ì´ ì¶©ì¡±
            # 5. í‚¤ì›Œë“œ ë°˜ì˜ (30% ì´ìƒ)
            # 6. ê°ì • ë°˜ì˜ (50% ì´ìƒ)
            
            # ê° ì¡°ê±´ë³„ í™•ì¸ (ë””ë²„ê¹…ìš©) - ê¸°ì¤€ ì™„í™”
            check_poetry_score = poetry_quality['overall_score'] >= 0.5  # 0.6 â†’ 0.5ë¡œ ì™„í™”
            check_not_prose = not poetry_quality.get('is_prose', False)
            check_not_diary = not poetry_quality.get('is_diary', False)
            check_not_explanation = not poetry_quality.get('is_explanation', False)
            check_korean_chars = poetry_quality['korean_chars'] >= 10  # 15 â†’ 10ìœ¼ë¡œ ì™„í™”
            check_line_count = poetry_quality.get('line_count', 0) >= 2  # 3 â†’ 2ë¡œ ì™„í™”
            check_min_length = len(generated_poem.strip()) >= 20  # 25 â†’ 20ìœ¼ë¡œ ì™„í™”
            check_keyword = keyword_relevance['keyword_coverage'] >= 0.2  # 30% â†’ 20%ë¡œ ì™„í™”
            check_emotion = emotion_relevance['emotion_score'] >= 0.4  # 0.5 â†’ 0.4ë¡œ ì™„í™”
            
            # ì„±ê³µ ê¸°ì¤€: ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì ìˆ˜ ì‹œìŠ¤í…œ
            # í•„ìˆ˜ ì¡°ê±´ì„ ì ìˆ˜ë¡œ ë³€í™˜ (í†µê³¼í•œ ê°œìˆ˜ì— ë”°ë¼ ì ìˆ˜ ë¶€ì—¬)
            required_checks = [
                check_not_prose,  # ì‚°ë¬¸ì´ ì•„ë‹ˆë©´ í†µê³¼
                check_not_diary,  # ì¼ê¸°ê°€ ì•„ë‹ˆë©´ í†µê³¼
                check_not_explanation,  # ì„¤ëª…ë¬¸ì´ ì•„ë‹ˆë©´ í†µê³¼
                check_korean_chars,  # í•œê¸€ 10ì ì´ìƒì´ë©´ í†µê³¼
            ]
            
            # í•„ìˆ˜ ì¡°ê±´ í†µê³¼ ê°œìˆ˜ì— ë”°ë¥¸ ì ìˆ˜ (0.0 ~ 1.0)
            passed_required_count = sum(required_checks)
            required_score = passed_required_count / len(required_checks)  # 4ê°œ ì¤‘ ëª‡ ê°œ í†µê³¼í–ˆëŠ”ì§€ ë¹„ìœ¨
            
            # ì„ íƒ ì¡°ê±´: ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°
            # ê° ì¡°ê±´ì„ ì ìˆ˜ë¡œ ë³€í™˜ (0.0 ~ 1.0) - ê¸°ì¤€ ì™„í™”
            score_poetry = min(1.0, poetry_quality['overall_score'] / 0.5)  # 0.5 ì´ìƒì´ë©´ 1.0
            score_line_count = min(1.0, poetry_quality.get('line_count', 0) / 2.0)  # 2ì¤„ ì´ìƒì´ë©´ 1.0
            score_min_length = min(1.0, len(generated_poem.strip()) / 20.0) if generated_poem else 0.0  # 20ì ì´ìƒì´ë©´ 1.0
            score_keyword = min(1.0, keyword_relevance['keyword_coverage'] / 0.2)  # 20% ì´ìƒì´ë©´ 1.0
            score_emotion = min(1.0, emotion_relevance['emotion_score'] / 0.4)  # 0.4 ì´ìƒì´ë©´ 1.0
            
            # ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì¢…í•© ì ìˆ˜ ê³„ì‚°
            # í•„ìˆ˜ ì¡°ê±´ ì ìˆ˜ 30% + ì„ íƒ ì¡°ê±´ ì ìˆ˜ 70%
            # ì„ íƒ ì¡°ê±´ ì¤‘ ì‹œ í’ˆì§ˆì´ ê°€ì¥ ì¤‘ìš” (40%), ë‚˜ë¨¸ì§€ëŠ” ê° 10%
            selection_score = (
                score_poetry * 0.40 +
                score_line_count * 0.10 +
                score_min_length * 0.10 +
                score_keyword * 0.20 +
                score_emotion * 0.20
            )
            
            # ì¢…í•© ì ìˆ˜ = í•„ìˆ˜ ì¡°ê±´ ì ìˆ˜(30%) + ì„ íƒ ì¡°ê±´ ì ìˆ˜(70%)
            weighted_score = (required_score * 0.30) + (selection_score * 0.70)
            
            # ì¢…í•© ì ìˆ˜ê°€ 0.6 ì´ìƒì´ë©´ ì„±ê³µ
            is_success = weighted_score >= 0.6
            
            # ë””ë²„ê¹…: ì²˜ìŒ 5ê°œ ìƒ˜í”Œì— ëŒ€í•´ ìƒì„¸ ë¶„ì„ ì¶œë ¥
            if sample_count <= 5:
                print(f"\n    [ìƒ˜í”Œ {sample_count} í‰ê°€ ê²°ê³¼]")
                print(f"      ì›ë¬¸: {text[:60]}...")
                print(f"      ìƒì„±ëœ ì‹œ: {repr(generated_poem[:150]) if generated_poem else 'None'}")
                
                if not is_success:
                    print(f"      ê²°ê³¼: âŒ ì‹¤íŒ¨")
                else:
                    print(f"      ê²°ê³¼: âœ… ì„±ê³µ")
                
                # í•„ìˆ˜ ì¡°ê±´ í™•ì¸
                print(f"\n      [í•„ìˆ˜ ì¡°ê±´] (í†µê³¼ ê°œìˆ˜ì— ë”°ë¼ ì ìˆ˜ ë¶€ì—¬: {passed_required_count}/4)")
                print(f"        ì‚°ë¬¸ ì—¬ë¶€: {poetry_quality.get('is_prose', False)} {'âœ…' if check_not_prose else 'âŒ'}")
                if poetry_quality.get('is_prose', False):
                    print(f"          - ì„ ì–¸ì  ì¢…ê²°ì–´ë¯¸: {poetry_quality.get('declarative_count', 0)}ê°œ")
                    print(f"          - ì£¼ì–´/ì‹œê°„ í‘œì‹œ: {poetry_quality.get('subject_time_count', 0)}ê°œ")
                print(f"        ì¼ê¸° ì—¬ë¶€: {poetry_quality.get('is_diary', False)} {'âœ…' if check_not_diary else 'âŒ'}")
                if poetry_quality.get('is_diary', False):
                    print(f"          - ì¼ê¸° íŒ¨í„´: {poetry_quality.get('diary_count', 0)}ê°œ")
                print(f"        ì„¤ëª…ë¬¸ ì—¬ë¶€: {poetry_quality.get('is_explanation', False)} {'âœ…' if check_not_explanation else 'âŒ'}")
                if poetry_quality.get('is_explanation', False):
                    print(f"          - ì„¤ëª…ë¬¸ íŒ¨í„´: {poetry_quality.get('explanation_count', 0)}ê°œ")
                print(f"        í•œê¸€ ë¬¸ì: {poetry_quality['korean_chars']}ì (í•„ìš”: â‰¥10) {'âœ…' if check_korean_chars else 'âŒ'}")
                print(f"        â†’ í•„ìˆ˜ ì¡°ê±´ ì ìˆ˜: {required_score:.4f} ({passed_required_count}/4 í†µê³¼)")
                
                # ì„ íƒ ì¡°ê±´ í™•ì¸
                print(f"\n      [ì„ íƒ ì¡°ê±´] (ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì ìˆ˜)")
                print(f"        ì‹œ í’ˆì§ˆ ì ìˆ˜: {poetry_quality['overall_score']:.4f} (ëª©í‘œ: â‰¥0.5)")
                print(f"        ì¤„ ê°œìˆ˜: {poetry_quality.get('line_count', 0)}ì¤„ (ëª©í‘œ: â‰¥2)")
                print(f"        ì „ì²´ ê¸¸ì´: {len(generated_poem.strip()) if generated_poem else 0}ì (ëª©í‘œ: â‰¥20)")
                print(f"        í‚¤ì›Œë“œ ë°˜ì˜ë¥ : {keyword_relevance['keyword_coverage']:.2%} (ëª©í‘œ: â‰¥20%)")
                print(f"        ê°ì • ì ìˆ˜: {emotion_relevance['emotion_score']:.4f} (ëª©í‘œ: â‰¥0.4)")
                
                # ì¢…í•© ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘ì¹˜ ê¸°ë°˜)
                print(f"\n        ì¢…í•© ì ìˆ˜ ê³„ì‚°:")
                print(f"          - í•„ìˆ˜ ì¡°ê±´ ì ìˆ˜: {required_score:.4f} Ã— 0.30 = {required_score * 0.30:.4f}")
                print(f"          - ì„ íƒ ì¡°ê±´ ì ìˆ˜: {selection_score:.4f} Ã— 0.70 = {selection_score * 0.70:.4f}")
                print(f"          - ì¢…í•© ì ìˆ˜: {weighted_score:.4f} (í•„ìš”: â‰¥0.6)")
                print(f"\n        ì„ íƒ ì¡°ê±´ ì„¸ë¶€:")
                print(f"          - ì‹œ í’ˆì§ˆ: {score_poetry:.4f} Ã— 0.40 = {score_poetry * 0.40:.4f}")
                print(f"          - ì¤„ ê°œìˆ˜: {score_line_count:.4f} Ã— 0.10 = {score_line_count * 0.10:.4f}")
                print(f"          - ì „ì²´ ê¸¸ì´: {score_min_length:.4f} Ã— 0.10 = {score_min_length * 0.10:.4f}")
                print(f"          - í‚¤ì›Œë“œ: {score_keyword:.4f} Ã— 0.20 = {score_keyword * 0.20:.4f}")
                print(f"          - ê°ì •: {score_emotion:.4f} Ã— 0.20 = {score_emotion * 0.20:.4f}")
            
            if is_success:
                success_count += 1
            
            results.append({
                'original_text': text,
                'original_poem': original_poem,
                'generated_poem': generated_poem,
                'keywords': keywords,
                'mood': mood,
                'success': is_success,
                'poetry_quality': poetry_quality,
                'keyword_relevance': keyword_relevance,
                'emotion_relevance': emotion_relevance,
                'similarity': similarity
            })
            
        except Exception as e:
            print(f"    âš ï¸ ì˜¤ë¥˜ (ì¸ë±ìŠ¤ {i-1}): {e}")
            results.append({
                'original_text': text,
                'original_poem': original_poem,
                'generated_poem': '',
                'success': False,
                'error': str(e)
            })
    
    # ê²°ê³¼ ì •ë¦¬
    avg_similarity = np.mean(similarities) if similarities else 0.0
    success_rate = success_count / len(test_data) if test_data else 0.0
    
    # ì‹œ í’ˆì§ˆ ì ìˆ˜ í‰ê· 
    poetry_scores = [r.get('poetry_quality', {}).get('overall_score', 0.0) 
                     for r in results if r.get('poetry_quality')]
    avg_poetry_score = np.mean(poetry_scores) if poetry_scores else 0.0
    
    # í‚¤ì›Œë“œ ê´€ë ¨ì„± í‰ê· 
    keyword_scores = [r.get('keyword_relevance', {}).get('keyword_score', 0.0) 
                      for r in results if r.get('keyword_relevance')]
    avg_keyword_score = np.mean(keyword_scores) if keyword_scores else 0.0
    avg_keyword_coverage = np.mean([r.get('keyword_relevance', {}).get('keyword_coverage', 0.0) 
                                    for r in results if r.get('keyword_relevance')]) if keyword_scores else 0.0
    
    # ê°ì • ê´€ë ¨ì„± í‰ê· 
    emotion_scores = [r.get('emotion_relevance', {}).get('emotion_score', 0.0) 
                      for r in results if r.get('emotion_relevance')]
    avg_emotion_score = np.mean(emotion_scores) if emotion_scores else 0.0
    avg_emotion_match = np.mean([r.get('emotion_relevance', {}).get('emotion_match', 0.0) 
                                 for r in results if r.get('emotion_relevance')]) if emotion_scores else 0.0
    
    # ìƒì„¸ í†µê³„
    avg_format_score = np.mean([r.get('poetry_quality', {}).get('format_score', 0.0) 
                                for r in results if r.get('poetry_quality')]) if poetry_scores else 0.0
    avg_korean_score = np.mean([r.get('poetry_quality', {}).get('korean_score', 0.0) 
                                   for r in results if r.get('poetry_quality')]) if poetry_scores else 0.0
    avg_prose_penalty = np.mean([r.get('poetry_quality', {}).get('prose_penalty', 0.0) 
                                 for r in results if r.get('poetry_quality')]) if poetry_scores else 0.0
    avg_poetry_bonus = np.mean([r.get('poetry_quality', {}).get('poetry_bonus', 0.0) 
                                for r in results if r.get('poetry_quality')]) if poetry_scores else 0.0
    
    # ì‚°ë¬¸/ì¼ê¸°/ì„¤ëª…ë¬¸ í†µê³„
    prose_count = sum(1 for r in results if r.get('poetry_quality', {}).get('is_prose', False))
    diary_count = sum(1 for r in results if r.get('poetry_quality', {}).get('is_diary', False))
    explanation_count = sum(1 for r in results if r.get('poetry_quality', {}).get('is_explanation', False))
    
    print(f"\n[3/3] í‰ê°€ ì™„ë£Œ")
    print(f"  - ì„±ê³µë¥  (ì¢…í•© ê¸°ì¤€): {success_rate:.2%} ({success_count}/{len(test_data)})")
    
    # ì„±ê³µë¥ ì´ 0%ì¸ ê²½ìš° ìƒì„¸ ë¶„ì„
    if success_rate == 0.0:
        print(f"\n  âš ï¸ ì„±ê³µë¥ ì´ 0%ì…ë‹ˆë‹¤. ì‹¤íŒ¨ ì›ì¸ ë¶„ì„:")
        
        # í•„ìˆ˜ ì¡°ê±´ ì‹¤íŒ¨ í†µê³„
        prose_fail = sum(1 for r in results if r.get('poetry_quality', {}).get('is_prose', False))
        diary_fail = sum(1 for r in results if r.get('poetry_quality', {}).get('is_diary', False))
        explanation_fail = sum(1 for r in results if r.get('poetry_quality', {}).get('is_explanation', False))
        korean_chars_fail = sum(1 for r in results if r.get('poetry_quality', {}).get('korean_chars', 0) < 15)
        
        # ì„ íƒ ì¡°ê±´ ì‹¤íŒ¨ í†µê³„
        poetry_score_fail = sum(1 for r in results if r.get('poetry_quality', {}).get('overall_score', 0.0) < 0.6)
        line_count_fail = sum(1 for r in results if r.get('poetry_quality', {}).get('line_count', 0) < 3)
        min_length_fail = sum(1 for r in results if len(r.get('generated_poem', '').strip()) < 25)
        keyword_fail = sum(1 for r in results if r.get('keyword_relevance', {}).get('keyword_coverage', 0.0) < 0.3)
        emotion_fail = sum(1 for r in results if r.get('emotion_relevance', {}).get('emotion_score', 0.0) < 0.5)
        
        # í•„ìˆ˜ ì¡°ê±´ ì‹¤íŒ¨ë¡œ ì¸í•œ ì‹¤íŒ¨
        required_fail = prose_fail + diary_fail + explanation_fail + korean_chars_fail
        
        print(f"\n    [í•„ìˆ˜ ì¡°ê±´ ì‹¤íŒ¨] (í•˜ë‚˜ë¼ë„ ì‹¤íŒ¨í•˜ë©´ ì‹¤íŒ¨)")
        print(f"      - ì‚°ë¬¸ìœ¼ë¡œ íŒì •: {prose_fail}ê°œ")
        print(f"      - ì¼ê¸°ë¡œ íŒì •: {diary_fail}ê°œ")
        print(f"      - ì„¤ëª…ë¬¸ìœ¼ë¡œ íŒì •: {explanation_fail}ê°œ")
        print(f"      - í•œê¸€ < 10ì: {korean_chars_fail}ê°œ")
        print(f"      â†’ í•„ìˆ˜ ì¡°ê±´ ì‹¤íŒ¨ë¡œ ì¸í•œ ì‹¤íŒ¨: {required_fail}ê°œ")
        
        # ì„ íƒ ì¡°ê±´ ë¶„ì„
        print(f"\n    [ì„ íƒ ì¡°ê±´ ë¶„ì„]")
        print(f"      - ì‹œ í’ˆì§ˆ ì ìˆ˜ < 0.5: {poetry_score_fail}ê°œ")
        print(f"      - ì¤„ ê°œìˆ˜ < 2ì¤„: {line_count_fail}ê°œ")
        print(f"      - ì „ì²´ ê¸¸ì´ < 20ì: {min_length_fail}ê°œ")
        print(f"      - í‚¤ì›Œë“œ ë°˜ì˜ë¥  < 20%: {keyword_fail}ê°œ")
        print(f"      - ê°ì • ì ìˆ˜ < 0.4: {emotion_fail}ê°œ")
        
        # ì¢…í•© ì ìˆ˜ í†µê³„ (ëª¨ë“  ìƒ˜í”Œì— ëŒ€í•´ ê³„ì‚°)
        weighted_scores = []
        for r in results:
            poetry_q = r.get('poetry_quality', {})
            keyword_r = r.get('keyword_relevance', {})
            emotion_r = r.get('emotion_relevance', {})
            
            # í•„ìˆ˜ ì¡°ê±´ í†µê³¼ ê°œìˆ˜ ê³„ì‚°
            required_pass_count = 0
            if not poetry_q.get('is_prose', False):
                required_pass_count += 1
            if not poetry_q.get('is_diary', False):
                required_pass_count += 1
            if not poetry_q.get('is_explanation', False):
                required_pass_count += 1
            if poetry_q.get('korean_chars', 0) >= 10:
                required_pass_count += 1
            
            required_score = required_pass_count / 4.0
            
            # ì„ íƒ ì¡°ê±´ ì ìˆ˜ ê³„ì‚°
            score_poetry = min(1.0, poetry_q.get('overall_score', 0.0) / 0.5)
            score_line_count = min(1.0, poetry_q.get('line_count', 0) / 2.0)
            score_min_length = min(1.0, len(r.get('generated_poem', '').strip()) / 20.0)
            score_keyword = min(1.0, keyword_r.get('keyword_coverage', 0.0) / 0.2)
            score_emotion = min(1.0, emotion_r.get('emotion_score', 0.0) / 0.4)
            
            selection_score = (
                score_poetry * 0.40 +
                score_line_count * 0.10 +
                score_min_length * 0.10 +
                score_keyword * 0.20 +
                score_emotion * 0.20
            )
            
            # ì¢…í•© ì ìˆ˜ = í•„ìˆ˜ ì¡°ê±´ ì ìˆ˜(30%) + ì„ íƒ ì¡°ê±´ ì ìˆ˜(70%)
            weighted_score = (required_score * 0.30) + (selection_score * 0.70)
            weighted_scores.append(weighted_score)
        
        if weighted_scores:
            avg_weighted_score = np.mean(weighted_scores)
            max_weighted_score = np.max(weighted_scores)
            min_weighted_score = np.min(weighted_scores)
            below_06 = sum(1 for s in weighted_scores if s < 0.6)
            
            print(f"\n      ì¢…í•© ì ìˆ˜ í†µê³„:")
            print(f"        - í‰ê· : {avg_weighted_score:.4f}")
            print(f"        - ìµœê³ : {max_weighted_score:.4f}")
            print(f"        - ìµœì €: {min_weighted_score:.4f}")
            print(f"        - 0.6 ë¯¸ë§Œ: {below_06}ê°œ")
        
        # ìƒì„±ëœ ì‹œê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
        empty_poems = sum(1 for r in results if not r.get('generated_poem') or len(r.get('generated_poem', '').strip()) == 0)
        if empty_poems > 0:
            print(f"\n    âš ï¸ ìƒì„±ëœ ì‹œê°€ ë¹„ì–´ìˆìŒ: {empty_poems}ê°œ")
            print(f"    ğŸ’¡ ëª¨ë¸ì´ ì‹œë¥¼ ìƒì„±í•˜ì§€ ëª»í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
            print(f"    ğŸ’¡ ê°€ëŠ¥í•œ ì›ì¸:")
            print(f"       1. ëª¨ë¸ì´ ì œëŒ€ë¡œ í•™ìŠµë˜ì§€ ì•ŠìŒ")
            print(f"       2. ì…ë ¥ í˜•ì‹ì´ í•™ìŠµ ì‹œì™€ ë‹¤ë¦„")
            print(f"       3. ëª¨ë¸ì´ í”„ë¡¬í”„íŠ¸ë§Œ ë°˜ë³µí•˜ê³  ìˆìŒ")
        
        # ì‹¤ì œ ìƒì„±ëœ ì‹œ ìƒ˜í”Œ í™•ì¸
        non_empty_poems = [r for r in results if r.get('generated_poem') and len(r.get('generated_poem', '').strip()) > 0]
        if non_empty_poems:
            print(f"\n    ğŸ“ ìƒì„±ëœ ì‹œ ìƒ˜í”Œ (ì²˜ìŒ 3ê°œ):")
            for i, r in enumerate(non_empty_poems[:3], 1):
                poem = r.get('generated_poem', '')
                print(f"      [{i}] {repr(poem[:100])}")
                poetry_q = r.get('poetry_quality', {})
                print(f"          - ì‹œ í’ˆì§ˆ: {poetry_q.get('overall_score', 0.0):.4f}, "
                      f"ì‚°ë¬¸: {poetry_q.get('is_prose', False)}, "
                      f"í•œê¸€: {poetry_q.get('korean_chars', 0)}ì, "
                      f"ì¤„: {poetry_q.get('line_count', 0)}ì¤„")
    
    print(f"\n  ğŸ“ ì‹œ í˜•íƒœ í‰ê°€:")
    print(f"    - í‰ê·  ì‹œ í’ˆì§ˆ ì ìˆ˜: {avg_poetry_score:.4f} (0.0=ì‚°ë¬¸, 1.0=ì‹œ)")
    print(f"    - í‰ê·  í˜•ì‹ ì ìˆ˜: {avg_format_score:.4f}")
    print(f"    - í‰ê·  í•œêµ­ì–´ ì ìˆ˜: {avg_korean_score:.4f}")
    print(f"    - í‰ê·  ì‚°ë¬¸ íŒ¨ë„í‹°: {avg_prose_penalty:.4f}")
    print(f"    - í‰ê·  ì‹œì  í‘œí˜„ ë³´ë„ˆìŠ¤: {avg_poetry_bonus:.4f}")
    print(f"    - ì‚°ë¬¸ìœ¼ë¡œ íŒì •: {prose_count}ê°œ")
    print(f"    - ì¼ê¸°ë¡œ íŒì •: {diary_count}ê°œ")
    print(f"    - ì„¤ëª…ë¬¸ìœ¼ë¡œ íŒì •: {explanation_count}ê°œ")
    print(f"\n  ğŸ”‘ í‚¤ì›Œë“œ ë°˜ì˜ í‰ê°€:")
    print(f"    - í‰ê·  í‚¤ì›Œë“œ ì ìˆ˜: {avg_keyword_score:.4f} (0.0=ë°˜ì˜ ì•ˆë¨, 1.0=ì™„ë²½ ë°˜ì˜)")
    print(f"    - í‰ê·  í‚¤ì›Œë“œ ë°˜ì˜ë¥ : {avg_keyword_coverage:.2%} (í¬í•¨ëœ í‚¤ì›Œë“œ ë¹„ìœ¨)")
    print(f"\n  ğŸ’­ ê°ì • ë°˜ì˜ í‰ê°€:")
    print(f"    - í‰ê·  ê°ì • ì ìˆ˜: {avg_emotion_score:.4f} (0.0=ë°˜ì˜ ì•ˆë¨, 1.0=ì™„ë²½ ë°˜ì˜)")
    print(f"    - í‰ê·  ê°ì • ì¼ì¹˜ë„: {avg_emotion_match:.4f} (ì›ë³¸ ê°ì •ê³¼ ì¼ì¹˜í•˜ëŠ” ë¹„ìœ¨)")
    print(f"\n  ğŸ“Š ê¸°íƒ€:")
    print(f"    - í‰ê·  ìœ ì‚¬ë„ (ì›ë³¸ ì‹œì™€): {avg_similarity:.4f}")
    
    # ë””ë²„ê¹…: ìƒì„±ëœ ì‹œ ìƒ˜í”Œ í™•ì¸
    print(f"\n  [ë””ë²„ê¹… ì •ë³´]")
    successful_poems = [r for r in results if r.get('generated_poem') and len(r.get('generated_poem', '').strip()) > 0]
    print(f"  - ì‹œ ìƒì„± ì„±ê³µ: {len(successful_poems)}/{len(results)}")
    if successful_poems:
        print(f"  - ì²« ë²ˆì§¸ ìƒì„±ëœ ì‹œ ìƒ˜í”Œ:")
        print(f"    {repr(successful_poems[0]['generated_poem'][:150])}")
    else:
        print(f"  âš ï¸ ìƒì„±ëœ ì‹œê°€ ì—†ìŠµë‹ˆë‹¤!")
        if results:
            print(f"  - ì²« ë²ˆì§¸ ê²°ê³¼:")
            print(f"    {repr(results[0].get('generated_poem', 'None')[:150])}")
    
    # ë©”ëª¨ë¦¬ ì •ë¦¬
    del model
    del tokenizer
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    return {
        'fold': fold_idx,
        'success': True,
        'model_path': str(model_path),
        'test_count': len(test_data),
        'success_count': success_count,
        'success_rate': success_rate,
        'avg_poetry_score': avg_poetry_score,
        'avg_format_score': avg_format_score,
        'avg_korean_score': avg_korean_score,
        'avg_prose_penalty': avg_prose_penalty,
        'avg_keyword_score': avg_keyword_score,
        'avg_keyword_coverage': avg_keyword_coverage,
        'avg_emotion_score': avg_emotion_score,
        'avg_emotion_match': avg_emotion_match,
        'avg_similarity': avg_similarity,
        'results': results
    }


def find_best_fold_model(base_dir: str = None) -> None:
    """ëª¨ë“  fold ëª¨ë¸ì„ í‰ê°€í•˜ê³  ê°€ì¥ ì¢‹ì€ ëª¨ë¸ ì°¾ê¸°"""
    print(f"\n{'='*80}")
    print("k-fold ëª¨ë¸ ì„±ëŠ¥ í‰ê°€")
    print(f"{'='*80}\n")
    
    # GPU í™•ì¸
    if torch.cuda.is_available():
        device = "cuda"
        print(f"âœ… GPU ì‚¬ìš©: {torch.cuda.get_device_name(0)}")
    else:
        device = "cpu"
        print("âš ï¸ CPU ëª¨ë“œ (ëŠë¦¼)")
    
    # ëª¨ë¸ í´ë” ìë™ ì°¾ê¸°
    print(f"\n[0/4] ëª¨ë¸ í´ë” ì°¾ê¸°...")
    if base_dir is None:
        base_dir = BASE_MODEL_DIR
    
    base_path = Path(base_dir)
    
    # í´ë”ê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ì°¾ê¸°
    if not base_path.exists():
        print(f"âš ï¸ {base_dir} í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìë™ ê²€ìƒ‰ ì¤‘...")
        
        # í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ kogpt2 ê´€ë ¨ í´ë” ì°¾ê¸°
        current_dir = Path(".")
        possible_dirs = []
        
        for item in current_dir.iterdir():
            if item.is_dir() and "kogpt2" in item.name.lower():
                possible_dirs.append(item)
        
        if possible_dirs:
            print(f"\nğŸ“ ì°¾ì€ í´ë”:")
            for i, folder in enumerate(possible_dirs, 1):
                print(f"  {i}. {folder.name}")
            
            if len(possible_dirs) == 1:
                base_path = possible_dirs[0]
                print(f"\nâœ… ìë™ìœ¼ë¡œ ì„ íƒ: {base_path.name}")
            else:
                print(f"\nğŸ’¡ ì—¬ëŸ¬ í´ë”ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤. ì²« ë²ˆì§¸ í´ë”ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                base_path = possible_dirs[0]
                print(f"âœ… ì„ íƒ: {base_path.name}")
        else:
            print(f"\nâŒ kogpt2 ê´€ë ¨ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print(f"\nğŸ“ í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  í´ë”:")
            for item in current_dir.iterdir():
                if item.is_dir():
                    print(f"  - {item.name}")
            print(f"\nğŸ’¡ ì˜¬ë°”ë¥¸ í´ë” ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”:")
            user_input = input("í´ë” ê²½ë¡œ ì…ë ¥ (ê¸°ë³¸ê°’: ./kogpt2_finetuned): ").strip()
            if user_input:
                base_path = Path(user_input)
            else:
                base_path = Path("./kogpt2_finetuned")
    
    if not base_path.exists():
        print(f"âŒ {base_path} í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"âœ… ëª¨ë¸ í´ë”: {base_path.absolute()}")
    
    # ë°ì´í„° ë¡œë“œ
    print(f"\n[1/4] ë°ì´í„° ë¡œë“œ ì¤‘...")
    try:
        data = download_kpoem_data(max_size=MAX_DATA_SIZE)
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    if len(data) < K_FOLDS:
        print(f"âŒ ë°ì´í„° ê°œìˆ˜({len(data)})ê°€ fold ê°œìˆ˜({K_FOLDS})ë³´ë‹¤ ì ìŠµë‹ˆë‹¤.")
        return
    
    # k-fold ë¶„í•  (í•™ìŠµ ì‹œì™€ ë™ì¼í•œ ë¶„í• )
    print(f"\n[2/4] k-fold ë¶„í•  ì¤‘...")
    kf = KFold(n_splits=K_FOLDS, shuffle=True, random_state=42)
    
    # fold ëª¨ë¸ ì°¾ê¸° (í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ ì§ì ‘ ì°¾ê¸°)
    print(f"\nğŸ” Fold ëª¨ë¸ ê²€ìƒ‰ ì¤‘... (20251109_08ë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë¸ë§Œ)")
    current_dir = Path(".")
    all_fold_folders = []
    
    # í•„í„°ë§í•  ë‚ ì§œ/ì‹œê°„ íŒ¨í„´
    target_prefix = "20251109_08"
    
    for folder in current_dir.iterdir():
        if folder.is_dir() and "_fold" in folder.name and "kogpt2" in folder.name.lower():
            # 20251109_08ë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë¸ë§Œ í•„í„°ë§
            if target_prefix in folder.name:
                # fold ë²ˆí˜¸ ì¶”ì¶œ
                match = re.search(r'_fold(\d+)_', folder.name)
                if match:
                    fold_num = int(match.group(1))
                    all_fold_folders.append((fold_num, folder))
    
    # fold ë²ˆí˜¸ë³„ë¡œ ê·¸ë£¹í™”í•˜ê³  ìµœì‹  ê²ƒ ì„ íƒ
    fold_models = {}
    for fold_num, folder in all_fold_folders:
        if fold_num not in fold_models:
            fold_models[fold_num] = folder
        else:
            # ë” ìµœì‹  timestampë¥¼ ê°€ì§„ í´ë” ì„ íƒ
            current_timestamp = re.search(r'_(\d{8}_\d{6})', folder.name)
            existing_timestamp = re.search(r'_(\d{8}_\d{6})', fold_models[fold_num].name)
            if current_timestamp and existing_timestamp:
                if current_timestamp.group(1) > existing_timestamp.group(1):
                    fold_models[fold_num] = folder
    
    print(f"âœ… {len(fold_models)}ê°œì˜ fold ëª¨ë¸ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤:")
    for fold_num in sorted(fold_models.keys()):
        print(f"  - Fold {fold_num}: {fold_models[fold_num].name}")
    
    if len(fold_models) < K_FOLDS:
        print(f"\nâš ï¸ ê²½ê³ : {len(fold_models)}ê°œì˜ foldë§Œ ì°¾ì•˜ìŠµë‹ˆë‹¤. (ì˜ˆìƒ: {K_FOLDS}ê°œ)")
        print(f"   ì°¾ì€ fold: {sorted(fold_models.keys())}")
    
    # ê° fold ëª¨ë¸ì˜ ì‹¤ì œ ê²½ë¡œ í™•ì¸ (checkpoint í´ë”ê°€ ì•„ë‹Œ ìµœìƒìœ„ ëª¨ë¸)
    for fold_num in fold_models:
        model_folder = fold_models[fold_num]
        # config.jsonì´ ìµœìƒìœ„ì— ìˆëŠ”ì§€ í™•ì¸
        if (model_folder / "config.json").exists():
            print(f"  âœ… Fold {fold_num}: ìµœìƒìœ„ì— ëª¨ë¸ íŒŒì¼ ì¡´ì¬")
        else:
            # checkpoint í´ë” í™•ì¸
            checkpoint_folders = [f for f in model_folder.iterdir() 
                                 if f.is_dir() and "checkpoint" in f.name.lower()]
            if checkpoint_folders:
                # ê°€ì¥ í° ë²ˆí˜¸ì˜ checkpoint ì„ íƒ
                checkpoint_nums = []
                for cp in checkpoint_folders:
                    match = re.search(r'checkpoint-(\d+)', cp.name)
                    if match:
                        checkpoint_nums.append((int(match.group(1)), cp))
                
                if checkpoint_nums:
                    latest_checkpoint = max(checkpoint_nums, key=lambda x: x[0])[1]
                    fold_models[fold_num] = latest_checkpoint
                    print(f"  âœ… Fold {fold_num}: {latest_checkpoint.name} ì‚¬ìš©")
                else:
                    print(f"  âš ï¸ Fold {fold_num}: checkpoint ë²ˆí˜¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                print(f"  âš ï¸ Fold {fold_num}: ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    if not fold_models:
        print(f"âŒ fold ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"\nğŸ“ {base_dir} ë‚´ì˜ í´ë”:")
        for item in base_path.iterdir():
            if item.is_dir():
                print(f"  - {item.name}")
        return
    
    print(f"âœ… {len(fold_models)}ê°œì˜ fold ëª¨ë¸ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤:")
    for fold_num in sorted(fold_models.keys()):
        print(f"  - Fold {fold_num}: {fold_models[fold_num].name}")
    
    # ê° fold í‰ê°€
    print(f"\n[3/4] ê° fold ëª¨ë¸ í‰ê°€ ì¤‘...")
    all_results = []
    
    for fold_idx, (train_indices, test_indices) in enumerate(kf.split(data), 1):
        if fold_idx not in fold_models:
            print(f"âš ï¸ Fold {fold_idx} ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
            continue
        
        test_data = [data[i] for i in test_indices]
        model_path = fold_models[fold_idx]
        
        print(f"\n{'='*80}")
        print(f"[Fold {fold_idx} í‰ê°€ ì‹œì‘]")
        print(f"  - ì‚¬ìš©í•  ëª¨ë¸: {model_path.name}")
        print(f"  - ëª¨ë¸ ê²½ë¡œ: {model_path.absolute()}")
        print(f"  - Test ë°ì´í„°: {len(test_data)}ê°œ")
        print(f"{'='*80}")
        
        result = evaluate_fold_model(fold_idx, model_path, test_data, device)
        all_results.append(result)
        
        # ê° fold ê²°ê³¼ ì¦‰ì‹œ ì¶œë ¥ (ë””ë²„ê¹…)
        if result.get('success', False):
            print(f"\nâœ… Fold {fold_idx} í‰ê°€ ì™„ë£Œ:")
            print(f"   - ì„±ê³µë¥ : {result['success_rate']:.2%}")
            print(f"   - ì‹œ í’ˆì§ˆ: {result.get('avg_poetry_score', 0.0):.4f}")
            print(f"   - í•œêµ­ì–´ ì ìˆ˜: {result.get('avg_korean_score', 0.0):.4f}")
            # ìƒì„±ëœ ì‹œ ìƒ˜í”Œ ì¶œë ¥
            if result.get('results'):
                sample_results = [r for r in result['results'] if r.get('generated_poem')]
                if sample_results:
                    print(f"   - ìƒì„±ëœ ì‹œ ìƒ˜í”Œ:")
                    print(f"     {repr(sample_results[0]['generated_poem'][:100])}")
        else:
            print(f"\nâŒ Fold {fold_idx} í‰ê°€ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
            # ì‹¤íŒ¨í•œ ê²½ìš°ì—ë„ ìƒì„±ëœ ì‹œ í™•ì¸
            if result.get('results'):
                sample_results = [r for r in result['results'] if r.get('generated_poem')]
                if sample_results:
                    print(f"   - ìƒì„±ëœ ì‹œ ìƒ˜í”Œ (ì‹¤íŒ¨):")
                    print(f"     {repr(sample_results[0]['generated_poem'][:100])}")
    
    # ê²°ê³¼ ë¹„êµ
    print(f"\n[4/4] ê²°ê³¼ ë¹„êµ")
    print(f"{'='*80}")
    print(f"{'Fold':<6} {'ì„±ê³µë¥ ':<10} {'ì‹œí’ˆì§ˆ':<10} {'í‚¤ì›Œë“œ':<10} {'ê°ì •':<10} {'ì¢…í•©ì ìˆ˜':<10}")
    print(f"{'-'*80}")
    
    valid_results = [r for r in all_results if r.get('success', False)]
    
    if not valid_results:
        print("âŒ í‰ê°€ ì„±ê³µí•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì¢…í•© ì ìˆ˜ ê³„ì‚° (ì‹œ í˜•íƒœ 40% + í‚¤ì›Œë“œ 30% + ê°ì • 30%)
    for result in valid_results:
        poetry_score = result.get('avg_poetry_score', 0.0)
        keyword_score = result.get('avg_keyword_score', 0.0)
        emotion_score = result.get('avg_emotion_score', 0.0)
        result['composite_score'] = (poetry_score * 0.4) + (keyword_score * 0.3) + (emotion_score * 0.3)
    
    for result in sorted(valid_results, key=lambda x: x['fold']):
        print(f"Fold {result['fold']:<4} "
              f"{result['success_rate']:>6.2%}   "
              f"{result.get('avg_poetry_score', 0.0):>6.4f}   "
              f"{result.get('avg_keyword_score', 0.0):>6.4f}   "
              f"{result.get('avg_emotion_score', 0.0):>6.4f}   "
              f"{result.get('composite_score', 0.0):>6.4f}")
    
    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì°¾ê¸°
    print(f"\n{'='*80}")
    print("ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸")
    print(f"{'='*80}")
    
    # ê° í•­ëª©ë³„ ìµœê³  ëª¨ë¸
    best_by_poetry = max(valid_results, key=lambda x: x.get('avg_poetry_score', 0.0))
    best_by_keyword = max(valid_results, key=lambda x: x.get('avg_keyword_score', 0.0))
    best_by_emotion = max(valid_results, key=lambda x: x.get('avg_emotion_score', 0.0))
    best_by_success = max(valid_results, key=lambda x: x['success_rate'])
    
    # ì¢…í•© ì ìˆ˜ëŠ” ì´ë¯¸ ê³„ì‚°ë¨ (composite_score)
    best_overall = max(valid_results, key=lambda x: x.get('composite_score', 0.0))
    
    print(f"\nğŸ“Š ì‹œ í˜•íƒœ ê¸°ì¤€ ìµœê³ : Fold {best_by_poetry['fold']}")
    print(f"   - ì‹œ í’ˆì§ˆ ì ìˆ˜: {best_by_poetry.get('avg_poetry_score', 0.0):.4f}")
    print(f"   - ì„±ê³µë¥ : {best_by_poetry['success_rate']:.2%}")
    print(f"   - í•œêµ­ì–´ ì ìˆ˜: {best_by_poetry.get('avg_korean_score', 0.0):.4f}")
    print(f"   - ì‚°ë¬¸ íŒ¨ë„í‹°: {best_by_poetry.get('avg_prose_penalty', 0.0):.4f}")
    
    print(f"\nğŸ”‘ í‚¤ì›Œë“œ ë°˜ì˜ ê¸°ì¤€ ìµœê³ : Fold {best_by_keyword['fold']}")
    print(f"   - í‚¤ì›Œë“œ ì ìˆ˜: {best_by_keyword.get('avg_keyword_score', 0.0):.4f}")
    print(f"   - í‚¤ì›Œë“œ ë°˜ì˜ë¥ : {best_by_keyword.get('avg_keyword_coverage', 0.0):.2%}")
    print(f"   - ì„±ê³µë¥ : {best_by_keyword['success_rate']:.2%}")
    
    print(f"\nğŸ’­ ê°ì • ë°˜ì˜ ê¸°ì¤€ ìµœê³ : Fold {best_by_emotion['fold']}")
    print(f"   - ê°ì • ì ìˆ˜: {best_by_emotion.get('avg_emotion_score', 0.0):.4f}")
    print(f"   - ê°ì • ì¼ì¹˜ë„: {best_by_emotion.get('avg_emotion_match', 0.0):.4f}")
    print(f"   - ì„±ê³µë¥ : {best_by_emotion['success_rate']:.2%}")
    
    print(f"\nğŸ“Š ì„±ê³µë¥  ê¸°ì¤€ ìµœê³ : Fold {best_by_success['fold']}")
    print(f"   - ì„±ê³µë¥ : {best_by_success['success_rate']:.2%}")
    print(f"   - ì¢…í•© ì ìˆ˜: {best_by_success.get('composite_score', 0.0):.4f}")
    
    print(f"\nğŸ† ì¢…í•© ìµœê³ : Fold {best_overall['fold']}")
    print(f"   - ì¢…í•© ì ìˆ˜: {best_overall.get('composite_score', 0.0):.4f}")
    print(f"   - ì‹œ í’ˆì§ˆ ì ìˆ˜: {best_overall.get('avg_poetry_score', 0.0):.4f}")
    print(f"   - í‚¤ì›Œë“œ ì ìˆ˜: {best_overall.get('avg_keyword_score', 0.0):.4f}")
    print(f"   - ê°ì • ì ìˆ˜: {best_overall.get('avg_emotion_score', 0.0):.4f}")
    print(f"   - ì„±ê³µë¥ : {best_overall['success_rate']:.2%}")
    print(f"   - ê²½ë¡œ: {best_overall['model_path']}")
    
    print(f"\nğŸ’¡ ì¶”ì²œ: Fold {best_overall['fold']} ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”!")
    print(f"   ë‹¤ìš´ë¡œë“œ ì½”ë“œ:")
    print(f"   ```python")
    print(f"   import shutil")
    print(f"   from google.colab import files")
    print(f"   fold_folder = \"{Path(best_overall['model_path']).name}\"")
    print(f"   base_dir = \"{base_path}\"")
    print(f"   shutil.make_archive(fold_folder, 'zip', base_dir, fold_folder)")
    print(f"   files.download(f\"{{fold_folder}}.zip\")")
    print(f"   ```")


if __name__ == "__main__":
    find_best_fold_model()

